{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c16f2c19-3e85-4fc5-9c75-7fec8edda95f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Setup\n",
    "\n",
    "Before running this notebook, update the `config.py` file with your catalog and schema names.  \n",
    "A dedicated compute cluster is required to run this notebook:  \n",
    "- Use **Approach 1** with Classic Compute  \n",
    "- Use **Approach 2** with Serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7330664f-e46e-4587-8f10-e30fd91dadf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Run this cell to initialize resource names. You can edit resource names in the config file before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "765f10e4-1842-4c14-bfec-96032d10bcae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfa1b080-5c57-47d4-b01e-2587fdb785ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Write data from CSV to schema to use with AI funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "709152f8-3cca-46d8-a06a-8a863bd732f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/synthetic_car_data.csv')\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{schema_name}.synthetic_car_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad489430-4667-4d2d-b2b0-6d6005c1a788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Write data from PNG to schema to use with AI funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1989542-365d-4ecd-a81d-97d1f0c0c7b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'file:/Workspace/Users/respinozahe@alumni.unav.es/Agent-Bricks-Workshop/data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.path.dirname(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get())\n",
    "data_path = f\"file:/Workspace{current_dir}/data\"\n",
    "display(data_path)\n",
    "file_path = f\"/Volumes/{catalog_name}/{schema_name}/dip/dip.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ade7f86d-29f4-42ec-a0ac-2fcaaa66a615",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Write data from ZIP file to use with Agent Bricks \n",
    "\n",
    "### Approach #1: Clone and Move Data from GitHub\n",
    "\n",
    "You need a classic compute cluster (not serverless) to move files from the workspace to a UC volume.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d4841b4-6301-47a8-b624-2cc195f7b287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'/Workspace/Users/respinozahe@alumni.unav.es/Agent-Bricks-Workshop/data/tech_support.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"/Workspace{current_dir}/data/tech_support.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38d7215-a5c0-4055-824d-8cda16682d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos descomprimidos en: /Workspace/Users/respinozahe@alumni.unav.es/Agent-Bricks-Workshop/data/tech_support/\nArchivos copiados exitosamente a: /Volumes/agent_bricks_demo/data_schema/tech_support/\n\nArchivos en el volumen (4 elementos):\n  - __MACOSX/\n  - knowledge_base/\n  - support_tickets/\n  - tech_support/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Tus rutas actuales\n",
    "current_dir = os.path.dirname(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get())\n",
    "\n",
    "# 1. Descomprimir en /Workspace\n",
    "zip_path = f\"/Workspace{current_dir}/data/tech_support.zip\"\n",
    "extract_path = f\"/Workspace{current_dir}/data/tech_support/\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "    print(f\"Archivos descomprimidos en: {extract_path}\")\n",
    "\n",
    "# 2. Limpiar archivos .DS_Store\n",
    "def delete_ds_store_files(root_dir):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename == '.DS_Store':\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not delete {file_path}: {e}\")\n",
    "\n",
    "delete_ds_store_files(extract_path)\n",
    "\n",
    "# 3. Crear volumen\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.`tech_support`\")\n",
    "\n",
    "# 4. Copiar directamente de /Workspace a /Volumes usando Python\n",
    "source_path = extract_path\n",
    "target_path = f\"/Volumes/{catalog_name}/{schema_name}/tech_support/\"\n",
    "\n",
    "# Crear directorio destino si no existe\n",
    "os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "# Copiar recursivamente\n",
    "shutil.copytree(source_path, target_path, dirs_exist_ok=True)\n",
    "\n",
    "print(f\"Archivos copiados exitosamente a: {target_path}\")\n",
    "\n",
    "# 5. Verificar archivos copiados\n",
    "files = dbutils.fs.ls(f\"/Volumes/{catalog_name}/{schema_name}/tech_support/\")\n",
    "print(f\"\\nArchivos en el volumen ({len(files)} elementos):\")\n",
    "for f in files[:5]:  # Mostrar primeros 5\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56fecc90-b013-4c94-96f4-7e9ae971b8ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Approach #2: Uploading Data Directly to a Unity Catalog Volume\n",
    "\n",
    "1. Download the Data </br>\n",
    "Download the tech_support.zip archive from the provided GitHub [link](https://github.com/chen-data-ai/Agent-Bricks-Workshop/blob/main/data/tech_support.zip).\n",
    "\n",
    "2. Upload the ZIP File </br>\n",
    "Go to your Databricks workspace.\n",
    "Navigate to your schema’s Unity Catalog volume using one of these methods:\n",
    "\n",
    "    - Sidebar: Select Add data > Upload files to volume\n",
    "    - Catalog Explorer: Click Add > Upload to volume\n",
    "    - Notebook: Select File > Upload the downloaded tech_support.zip file and your catalog or schema information\n",
    "\n",
    "3. Copy the File Path </br>\n",
    "After uploading, locate the file path (e.g., /Volumes/catalog/schema/volume/tech_support.zip) — you’ll need this path for the next step.\n",
    "\n",
    "4. Unzip the File in Databricks </br>\n",
    "Use the following command in a notebook cell to unzip the file to your desired directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aee1af5-c79a-409e-8f6f-0d735e750fdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sh unzip '/Volumes/<ADD YOUR CATALOG>/<ADD YOUR SCHEMA>/tech_support/tech_support.zip' -d '/Volumes/<ADD YOUR CATALOG>/<ADD YOUR SCHEMA>/tech_support'"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7358320039447319,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}